# dummy_drone
The Hand Gesture Controlled Drone system is designed to create a natural interaction between humans and machines. Using advanced image processing and neural network-based classification, the drone responds to predefined gestures, allowing users to guide its movement through intuitive hand signals.

 ğŸšğŸ–ï¸ğŸ™ï¸Hand-Gesture Controlled Drone (AIMS)

An AI-powered drone navigation system that converts real-time hand gestures and voice commands into accurate flight instructions using Computer Vision and Deep Learning. The system integrates MediaPipe for hand landmark detection, a Custom CNN for gesture classification, and voice recognition for command and emergency control.

ğŸ“Œ Project Summary

This software provides a touchless and voice-enabled interface for drone operation. By normalizing 21 hand landmarks, the system ensures reliable gesture recognition regardless of hand size or position. Additionally, voice detection enables users to issue commands or trigger emergency actions instantly.

ğŸš€ Core Features

â€¢ Real-Time Gesture Recognition: Low-latency command processing
â€¢ Voice Command Integration: Control drone using predefined voice inputs
â€¢ Emergency Voice Detection: Instant STOP or LAND on emergency keywords
â€¢ Landmark Normalization: Scale and position invariant recognition
â€¢ Dynamic Speed Control: Thumbâ€“index finger distance adjusts velocity
â€¢ 8 Gesture Commands: FORWARD, BACKWARD, LEFT, RIGHT, UP, DOWN, STOP, SPEED

ğŸ› ï¸ Technology Stack

â€¢ Programming Language: Python 3.8+
â€¢ Computer Vision: OpenCV, MediaPipe
â€¢ Deep Learning: TensorFlow / Keras (Custom CNN Model)
â€¢ Voice Recognition: SpeechRecognition / PyAudio
â€¢ Data Processing: NumPy, Pandas
