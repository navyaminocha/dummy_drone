# dummy_drone
The Hand Gesture Controlled Drone system is designed to create a natural interaction between humans and machines. Using advanced image processing and neural network-based classification, the drone responds to predefined gestures, allowing users to guide its movement through intuitive hand signals.

ğŸš Hand-Gesture Controlled Drone (AIMS) 

An AI-powered drone navigation system that converts live hand gestures into precise flight commands using Computer Vision and Deep Learning. The system leverages MediaPipe for hand landmark detection and a Custom CNN model for accurate gesture classification.

ğŸ“Œ Project Summary

This application enables contactless drone operation through an intuitive gesture-based interface. By extracting and normalizing 21 hand landmarks, the model ensures consistent recognition independent of hand size, orientation, or frame position.

ğŸš€ Core Features

â€¢ Real-Time Recognition: Ultra-low latency processing for smooth control
â€¢ Landmark Normalization: Scale and position invariant input data
â€¢ Dynamic Speed Adjustment: Thumbâ€“index finger distance controls velocity
â€¢ 8 Gesture Commands: FORWARD, BACKWARD, LEFT, RIGHT, UP, DOWN, STOP, SPEED

ğŸ› ï¸ Technology Stack

â€¢ Programming Language: Python 3.8+
â€¢ Computer Vision: OpenCV, MediaPipe
â€¢ Deep Learning Framework: TensorFlow / Keras (Custom CNN Model)
â€¢ Data Processing: NumPy, Pandas
